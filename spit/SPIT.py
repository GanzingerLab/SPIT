# -*- coding: utf-8 -*-
"""
Created on Mon Jul 28 14:36:43 2025

@author: castrolinares
"""

import os
import shutil
import csv
import json
import traceback
from glob import glob
from multiprocessing import freeze_support
from natsort import natsorted
import yaml as _yaml
import re
# import pickle
import numpy as np
import pandas as pd
import imageio
import yaml
from tqdm import tqdm
import tifffile as tiff
from scipy.ndimage import affine_transform
from picasso.io import load_movie, save_info
from picasso.localize import (
    get_spots,
    identify_async,
    identifications_from_futures,
)
import picasso.gausslq as gausslq
import picasso.avgroi as avgroi

from spit import tools
from spit import localize
from spit import linking as link
from spit import table as table
from spit import plot_diffusion
from spit import colocalize as coloc
from spit import plot_coloc

import os
import numpy as np

class SPIT_Run:
    """
    SPIT_Run
    ========

    Controller class for performing the full SPIT analysis workflow: affine image correction, 
    localization, ROI restriction, linking, and colocalization of fluorescence microscopy data.

    The class operates on an experiment folder containing raw `.raw` image files and corresponding
    metadata files (`*_result.txt`, `*_datalog.txt`). It uses user-defined `settings` defined in the running script
    to control each analysis step.

    Attributes
    ----------
    folder : str
        Path to the experiment folder containing raw image and result files.
    settings : object
        A configuration object containing sub-settings for registration, localization, linking,
        and colocalization. 
    output_folder : str
        Optional path to store processed outputs. Defaults to `folder` if not specified.
    image_folder : str
        Path to store intermediate and output image files. Automatically generated as:
        `<output_folder>/output/<folder_name>`.

    Methods
    -------
    affine_transform():
        Applies affine transformations (registration corrections) to all raw image channels
        based on the imaging setup (ANNAPURNA or K2).
    localize():
        Detects and fits fluorescent spots in processed TIFF image stacks.
    roi():
        Restricts localizations to manually drawn ROIs (from `.roi` files) and saves per-ROI
        localization tables. ROIs must be drawn in imageJ with the free-hand tool and saved in folder
        with the naming roiX.roi where X is an increasing integer. 
    link():
        Links localizations across frames to form particle trajectories using Trackpy, computes
        diffusion statistics.
    coloc_tracks():
        Identifies and analyzes colocalized particle tracks between two fluorescence channels.
    coloc_spots():
        Detects colocalized single-frame localizations between two fluorescence channels. Usually, link() must be used 
        after to get colocalized tracks with this method. Not supported for further analysis. 
    full_analysis_noROI(mode='tracks'):
        Runs a complete, automated analysis pipeline without ROI filtering (affine transform,
        localization, linking, colocalization).
    full_analysis_ROI(mode='tracks'):
        Runs a complete analysis pipeline including ROI restriction and downstream analysis. First affine_transform() must 
        be used independently, then ROIs must be drawn and the this function runs all the subsequent steps.
    table():
        Creates an overview table for the current run using the `table` module.
    _find_alternative_result_file(folder):
        Searches for result files in sibling folders if the expected ones are missing.

    Examples
    --------
    >>> run = SPIT_Run(r"C:\\Data\\Run_001", settings)
    >>> run.affine_transform()
    >>> run.localize()
    >>> run.link()
    >>> run.coloc_tracks()
    """
    def __init__(self, folder, settings, output_folder = None):
        self.folder = folder
        self.settings = settings
        if output_folder is None:
            self.output_folder = folder
        else:
            self.output_folder = output_folder
        self.image_folder = os.path.join(self.output_folder, 'output', self.folder.replace(self.output_folder, '')[1:])
    def affine_transform(self):     
        """
        Perform affine registration corrections and channel splitting.

        This step reads the `*_result.txt` and `*_datalog.txt` files generated by the microscope
        control system, determines which computer (ANNAPURNA or K2) performed the acquisition,
        and applies affine transformations and cropping to each fluorescence channel based on
        pre-calibrated transformation matrices.

        Steps:
        - Identify input `.raw` files and metadata.
        - Determine imaging setup (ANNAPURNA or K2).
        - Apply per-channel affine correction based on pre-made calibration matrices (`Hr`, `Hl`) to raw images.
        - Crop images to region of interest (ROI).
        - Save corrected TIFFs and YAML metadata per channel and pattern.

        Raises
        ------
        FileNotFoundError
            If the required `*_result.txt` or `*_datalog.txt` files are missing.
        """
        verticalROI = self.settings.registration_settings.verticalROI
        to_keep = self.settings.registration_settings.to_keep
        
        base_name = os.path.basename(self.folder)
        result_file = self.folder+'\\' +self.folder.split("\\")[-1]+'_result.txt'  #get direction result.txt file
        datalog_file = self.folder+'\\' +self.folder.split("\\")[-1]+'_datalog.txt' #get direction of datalog.txt file. 
        used_fallback = False
        if not (os.path.exists(result_file) and os.path.exists(datalog_file)):
            try:
                result_file, datalog_file = self._find_alternative_result_file(self.folder)
                used_fallback = True
            except FileNotFoundError as e:
                print(f"[Skip] {self.folder} — {e}")
                return
        result_txt=tools.read_result_file(result_file) #get a dictionary with the information in the result.txt file. 
         #define save folder. 
        if not os.path.exists(self.image_folder): #create the save folder if it does not exist. 
            os.makedirs(self.image_folder)
        if used_fallback:
            # Rename fallback files to match current folder name
            new_result_file = os.path.join(self.image_folder, base_name + '_result.txt')
            new_datalog_file = os.path.join(self.image_folder, base_name + '_datalog.txt')
            shutil.copy(result_file, new_result_file)
            shutil.copy(datalog_file, new_datalog_file)
            fallback_info_path = os.path.join(self.image_folder, 'FALLBACK_INFO.txt')
            with open(fallback_info_path, 'w') as f:
                f.write("Fallback result/datalog files were used.\n")
                f.write(f"Source folder: {os.path.dirname(result_file)}\n")
                f.write(f"Copied to: {self.image_folder}\n")
        else:
            # Keep original file names
            shutil.copy(result_file, self.image_folder)
            shutil.copy(datalog_file, self.image_folder)
        #check whether Annapurna or K2 was used and initialize the neceesary variables depening on that
        if result_txt['Computer'] == 'ANNAPURNA': 
            x_coords = self.settings.registration_settings.x_coords_annapurna
            Hl  = self.settings.load_H_left_annapurna()
            Hr = self.settings.load_H_right_annapurna()
            xlim, ylim = self.settings.load_crop_annapurna()
        elif result_txt['Computer'] == 'K2-BIVOUAC':
            x_coords = self.settings.registration_settings.x_coords_K2
            Hl  = self.settings.load_H_left_K2()
            Hr = self.settings.load_H_right_K2()
            xlim, ylim = self.settings.load_crop_K2()
        #check the imaging mode used: sequence or record (a.k.a VCR). 
        if result_txt['Mode'] == 'Sequence': #if you used sequence for that run
            pattern = tools.get_pattern(result_txt) #get the specific patterns that you used.
            self.split_ch = {}
            for pat, ch in pattern.items():  #and for each pattern
                file_name = os.path.join(self.folder, f"{os.path.basename(self.folder)}_{pat}.raw") #open the raw file
                d, inf = tools.load_raw(file_name)
                for i in ch: #for each channel that ahs been used in that specific pattern
                    ch = i.strip()
                    image = d[to_keep[0]:to_keep[1], verticalROI[0]:verticalROI[1], x_coords[ch][0]:x_coords[ch][1]] #Crop the image in the specific x_coordinates to use
                    if ch in ['405nm', '488nm']: #if the laser used is 405 or 488, use the right H matrix to correct. 
                        im = np.array(list(map(lambda img: tools.h_affine_transform(img, Hr), image)))
                    elif ch in ['638nm']: #if the laser used is the 638. used the left H matrix to correct. 
                        im = np.array(list(map(lambda img: tools.h_affine_transform(img, Hl), image)))
                    else: #If none of them have been used (561 laser), do not modify the image
                        im = np.copy(image)
                    cropped_im  = im[:, ylim[0]:ylim[1], xlim[0]:xlim[1]].astype(np.uint16) #crop the image in the proper cropping coordinates (after the correction). 
                    self.split_ch[ch] = np.copy(cropped_im)
                    yaml_path = os.path.join(self.image_folder, f"{pat}_{ch}.yaml")
                    with open(yaml_path, "w") as file: #save the .yaml file
                        _yaml.dump_all(inf, file, default_flow_style=False)
                    save = os.path.join(self.image_folder, f"{pat}_{ch}.tif") #save the image as .tif
                    imageio.mimwrite(save, cropped_im)    
        elif result_txt['Mode'] == 'VCR': #if you used record for that run
            pattern = tools.get_VCR_pattern(result_txt) #get the lasers that you used. 
            file_name = self.folder+'\\' +self.folder.split("\\")[-1]+'_'+'record'+'.raw'#open the raw file
            d, inf = tools.load_raw(file_name)
            self.split_ch = {}
            for ch, presence in pattern.items(): #for each laser used
                if presence: 
                    image = d[to_keep[0]:to_keep[1], verticalROI[0]:verticalROI[1], x_coords[ch][0]:x_coords[ch][1]] #crop the specific channel
                    if ch in ['405nm', '488nm']:#if the laser used is 405 or 488, use the right H matrix to correct. 
                        im = np.array(list(map(lambda img: tools.h_affine_transform(img, Hr), image)))
                    elif ch in ['638nm']:#if the laser used is the 638. used the left H matrix to correct. 
                        im = np.array(list(map(lambda img: tools.h_affine_transform(img, Hl), image)))
                    else:#If none of them have been used (561 laser has been used), do not modify the image
                        im = np.copy(image)
                    cropped_im  = im[:, ylim[0]:ylim[1], xlim[0]:xlim[1]].astype(np.uint16) #crop the image in the proper cropping coordinates (after the correction). 
                    self.split_ch[ch] = np.copy(cropped_im)
                    with open(os.path.join(self.image_folder, ch+'.yaml'), "w") as file:#save the .yaml file
                        _yaml.dump_all(inf, file, default_flow_style=False)
                    save = os.path.join(self.image_folder, ch+'.tif') #save the image as .tif
                    imageio.mimwrite(save, cropped_im)
        print('Finished with files in', self.folder.replace(self.output_folder, '')[1:])
    def localize(self): 
        """
        Detect and fit fluorescent spots (localizations) in TIFF stacks.

        This method loads each processed `.tif` file in the output directory and identifies
        spots using a gradient-based detector PICASSO. Spots are then fitted with the chosen algorithm:
        either least-squares Gaussian (`lq`, recommended) or center-of-mass (`com`, if the spots or not 
        circular do to excessively fast particles or small framerate).

        Steps:
        - Read all `.tif` files in `image_folder`.
        - Compute gradients and detect candidate spots.
        - Fit spots using the selected fitting algorithm.
        - Save localization tables (`*_locs.csv`) and corresponding `.yaml` metadata.
        - Optionally apply non-affine correction if enabled (not recommended).

        Notes
        -----
        - If `settings.localization_settings.plot` is True, generates diagnostic plots.

        Raises
        ------
        Exception
            If a TIFF file cannot be processed or contains no valid frames.
        """
        try:
            transformInfo = 'False' 
            #Actually not needed, because you can only add folders, based on a function in def main: 
            if os.path.isdir(self.image_folder): 
               print('Analyzing directory', self.image_folder)
               pathsTif = glob(self.image_folder + '/*.tif', recursive=True)
               paths = pathsTif
            # subdirectories = list({os.path.dirname(file_path) for file_path in paths})
               print(f'A total of {len(paths)} files detected...')
               print('--------------------------------------------------------')
            else:
                print(f'{self.folder} is not a folder')
                
            # If any of the folders does not contain tif or raw images, it will be skipped and the folder will be saved in the following list:
            skippedPaths = []  
            
            if paths: 
                movieList = []
                filelist = []
                self.locs = {}
                for i, path in enumerate(paths):
                    print(path)
                    if self.settings.localization_settings.skip in path or 'cluster_analysis' in path:
                        skippedPaths.append(path)
                        continue
                    
                    filelist.append(path)
                    movie, info = load_movie(path)
                    movieList.append(movie)
                    area = info[0]['Width']*info[0]['Height']*self.settings.get_px2um(path)*self.settings.get_px2um(path)
                    gradient = self.settings.gradient(path)
                    print(f'Localizing file {path}')
                    print('--------------------------------------------------------')
                    print('gradient:', self.settings.gradient(path))
                    
                    #Localize spots in the images based on the chosen fit-method
                    current, futures = identify_async(movie, gradient, self.settings.localization_settings.box)
                    ids = identifications_from_futures(futures)     
                    box = self.settings.localization_settings.box
                    camera_info = self.settings.localization_settings.camera_info
                    if self.settings.localization_settings.fit_method == 'lq':
                        spots = get_spots(movie, ids, box, camera_info)
                        theta = gausslq.fit_spots_parallel(spots, asynch=False)
                        locs = gausslq.locs_from_fits(ids, theta, box, camera_info['Gain'])
                    elif self.settings.localization_settings.fit_method == 'com':
                        spots = get_spots(movie, ids, box,camera_info)
                        theta = avgroi.fit_spots_parallel(spots, asynch=False)
                        locs = avgroi.locs_from_fits(ids, theta, box, camera_info['Gain'])
                    else:
                        print('This should never happen... Please, set a proper method: com for moving particles, lq for moving stuff')
                    #save the localizations in a dataframe        
                    df_locs = pd.DataFrame(locs)
                    # Compatibility with Swift
                    df_locs = df_locs.rename(columns={'frame': 't', 'photons': 'intensity'})
        
                    # adding localization precision, nearest neighbor, change photons, add cell_id column
                    df_locs['loc_precision'] = df_locs[['lpx', 'lpy']].mean(axis=1)
                    df_locs['nearest_neighbor'] = localize.get_nearest_neighbor(df_locs)
                    df_locs['cell_id'] = 0
    
                    # Non-affine correction only makes sense if we are dealing with two/three channel data. If you do not have these or want to update them, 
                    #use get_non-affine_coefs.py. 
                    if self.settings.localization_settings.transform:
                        #open non-affine coefficients. 
                        naclibCoefficients = self.settings.get_naclib(path)
                        #transform localizations based on the coefficients assigned to channel 2 (488nm or 405nm channel)
                        if '488nm' in path or '405nm' in path:
                            df_locs, dataset = localize.transform_locs(df_locs,
                                                                       naclibCoefficients,
                                                                       channel=2,
                                                                       fig_size=list(movie[0].shape[::-1]))
                            transformInfo = 'true, based on '+str(dataset)
                       #transform localizations based on the coefficients assigned to channel 0 (638nm channel)
                        elif '638nm' in path:
                            df_locs, dataset = localize.transform_locs(df_locs,
                                                                       naclibCoefficients,
                                                                       channel=0,
                                                                       fig_size=list(movie[0].shape[::-1]))
                            transformInfo = 'true, based on '+str(dataset)
                        #do not modify 531nm channel, since it is the reference channel.
                        else:
                            transformInfo = 'false, reference channel'
                   #update info (.yaml)            
                    localize_info = {
                        'Generated by': 'Picasso Localize',
                        'Box Size': self.settings.localization_settings.box,
                        'Min. Net Gradient': gradient,
                        'Color correction': transformInfo,
                        'Area': float(area),
                        'Fit method': self.settings.localization_settings.fit_method
                    }
                    info[0]["Byte Order"] = "<" #I manually checked with https://hexed.it/ that the tif files are still saved as little-endian
                    infoNew = info.copy()
                    infoNew.append(localize_info)
                    #get saving folder
                    base, ext = os.path.splitext(path)
         
                    pathChannel = base
        
                    pathOutput = pathChannel + self.settings.localization_settings.suffix + '_locs.csv'
                    #save localizations and ifnromation
                    df_locs.to_csv(pathOutput, index=False)
                    save_info(os.path.splitext(pathOutput)[0]+'.yaml', infoNew)
                    ch = pathOutput.split('\\')[-1].split('_')[-2]
                    self.locs[ch] = df_locs
                    
                    #plot, if asked for, the summary plots 
                    if self.settings.localization_settings.plot:
                        plotPath = tools.getOutputpath(
                            pathOutput, 'plots', keepFilename=True)
                        localize.plot_loc_stats(df_locs, plotPath)
    
                   
                    print(f'File saved to {pathOutput}')
                    print('                                                        ')
                 
        except:
            # "There are no files in this subfolder, rise error"
            skippedPaths.append(self.folder)
            print('Skipping...\n')
            print('--------------------------------------------------------')
    def roi(self):
        """
        Restrict localizations to user-defined ROIs.

        Loads `.roi` files (exported from ImageJ or Fiji with the freehand tool) from the `image_folder`,
        determines which localizations fall within each ROI, and saves filtered localization tables.

        Steps:
        - Load existing `*_locs.csv` files.
        - Parse `.roi` contours and compute area and centroid.
        - Filter localizations within each ROI.
        - Save new files as `*_roi_locs.csv` with updated metadata.

        Outputs
        -------
        - CSV files containing filtered localizations per ROI.
        - YAML metadata with ROI summary information.
        """
        # print(self.image_folder)
        # format filepaths
        
        print(self.image_folder)
        if os.path.isdir(self.image_folder):
            print('Analyzing directory...')
            paths = glob(self.image_folder + '/*nm_locs.csv')

        # initialize placeholders
        skippedPaths = []

        # print all kept paths
        for path in paths:
            print(path)
        print(f'A total of {len(paths)} files detected...')
        print('--------------------------------------------------------')
        self.locs_roi = {}
        # main loop
        for idx, path in tqdm(enumerate(paths), desc='Saving new loc-files...', total=len(paths)):
            print('--------------------------------------------------------')
            print(f'Running file {path}')
            try:
                (df_locs, info) = tools.load_locs(path)
                # Look for ROI paths
                pathsROI = natsorted(glob(os.path.dirname(path) + '/*.roi', recursive=False))
                print(f'Found {len(pathsROI)} ROI.')                
                dict_roi = {'cell_id': [], 'path': [], 'contour': [],
                            'area': [], 'roi_mask': [], 'centroid': []}
                
                # this stuff needs to go into tools
                
                df_locs = df_locs.drop('cell_id', axis=1)
                for idx, roi_path in enumerate(pathsROI):
                    roi_contour = tools.get_roi_contour(roi_path)
                    dict_roi['cell_id'].append(int(re.search(r'(\d+)\.roi$', roi_path).group(1)))
                    dict_roi['path'].append(roi_path)
                    dict_roi['contour'].append(roi_contour)
                    dict_roi['area'].append(tools.get_roi_area(roi_contour))
                    dict_roi['roi_mask'].append(
                        tools.get_roi_mask(df_locs, roi_contour))
                    dict_roi['centroid'].append(
                        tools.get_roi_centroid(roi_contour))

                df_roi = pd.DataFrame(dict_roi)
                
                df_locsM = pd.concat(
                    [df_locs[roi_mask] for roi_mask in df_roi.roi_mask],
                    keys=df_roi.cell_id.tolist()
                )


                df_locsM.index = df_locsM.index.set_names(['cell_id', None])
                df_locsM = df_locsM.reset_index(level=0)
                df_locsM = df_locsM.sort_values(['cell_id', 't'])
                df_locsM = df_locsM.drop_duplicates(subset=['x', 'y'])  # if ROIs overlap
                df_locs = df_locsM
                # get right output paths
                pathOutput = path.replace('locs.csv', 'roi_locs.csv')
                df_locs.to_csv(pathOutput, index=False)
                ch = pathOutput.split('\\')[-1].split('_')[-3]
                self.locs_roi[ch] = df_locs
                roi_info = {'Cell ROIs': str(df_roi.cell_id.unique())}
                infoNew = info.copy()
                infoNew.append(roi_info)
                save_info(os.path.splitext(pathOutput)[0] + '.yaml', infoNew)
            except Exception:
                skippedPaths.append(path)

                print('--------------------------------------------------------')
                print(f'Path {path} could not be analyzed. Skipping...\n')
                traceback.print_exc()

        print('                                                        ')
        print('--------------------------------------------------------')
        print('/////////////////////FINISHED//////////////////////////')
        print('--------------------------------------------------------')
        if skippedPaths:
            print('Skipped paths:')
            for skippedPath in skippedPaths:
                print(f'\n{skippedPath}\n')
    def link(self):
        """
        Link localizations across frames to form trajectories.

        Uses the `trackpy` algorithm (or optionally others) to link temporally consecutive
        localizations into tracks based on spatial proximity and frame distance. Supports
        both ROI and non-ROI runs.

        Steps:
        - Load `*_locs.csv` (or `*_roi_locs.csv` if ROI mode enabled).
        - Convert coordinates to nanometers.
        - Link particles using specified `search` and `memory` parameters.
        - Compute diffusion statistics and mean squared displacement (MSD).
        - Filter short or immobile tracks.
        - Save linked trajectories (`*_trackpy.csv`) and track stats (`*_stats.hdf`).

        Raises
        ------
        Exception
            If linking fails or if no valid trajectories are found.
        """
        try:
            if os.path.isdir(self.image_folder):
                if self.settings.link_settings.coloc:
                    paths = glob(self.image_folder + '/*colocs.csv', recursive=True)
                else:
                    paths = glob(self.image_folder + '/*_locs.csv', recursive=True)
                    
            skippedPaths = []
            quick = self.settings.link_settings.quick
            if self.settings.link_settings.coloc:
                self.tracks_coloc = {}
                self.tracks_coloc_stats = {}
            else:
                self.tracks = {}
                self.tracks_stats = {}
            # main loop
            for idx, path in tqdm(enumerate(paths), desc='Linking localizations...', total=len(paths)):
                try:
                    if self.settings.link_settings.roi and 'roi' not in path:
                        skip = path.split('\\')[-1]
                        print(f"\n\n Skipping {skip} bacause it is not filtered by roi and within Settings self.roi == {self.settings.link_settings.roi}\n")
                        continue
                    if not self.settings.link_settings.roi and 'roi' in path:
                        skip = path.split('\\')[-1]
                        print(f"\n\n Skipping {skip} bacause it is filtered by roi and within Settings self.roi == {self.settings.link_settings.roi}\n")
                        continue
                    (df_locs, info) = tools.load_locs(path)
                    if not self.settings.link_settings.coloc:
                        # fix locIDs before they get mixed up by linking
                        df_locs = df_locs.rename_axis('locID').reset_index()
            #         # retrieve exposure time
                    resultPath = '\\'.join(path.split('\\')[:-1]) + '\\' + [element for element in path.split('\\') if element.startswith('Run')][0] + '_result.txt'
                    if self.settings.link_settings.dt is not None:
                        dt = self.settings.link_settings.dt
                    else: 
                        resultTxt = open(resultPath, 'r')
                        resultLines = resultTxt.readlines()
                        if tools.find_string(resultLines, 'Interval'): 
                            interval = tools.find_string(resultLines, 'Interval').split(":")[-1].strip()
                            if interval.split(" ")[-1] == 'sec':
                                dt = 1.0 * int(float(interval.split(" ")[0]))
                            elif interval.split(" ")[-1] == 'ms':
                                dt = 0.001 * int(float(interval.split(" ")[0]))
                        else:
                            dtStr = tools.find_string(
                                resultLines, 'Camera Exposure')[17:-1]
                            dt = 0.001 * int(float((''.join(c for c in dtStr if (c.isdigit() or c == '.')))))
            
                    if 'roi' in path:
                        roi_boolean = True
                    else:
                        roi_boolean = False
            #         # Select 200px^2 center FOV and first 500 frames
                    if quick:
                        print(info[0])
                        img_size = info[0]['Height']  # get image size
                        roi_width = 100
                        if not roi_boolean:  # avoiding clash with ROIs-only limit frames
                            df_locs = df_locs[(df_locs.x > (img_size/2-roi_width))
                                              & (df_locs.x < (img_size/2+roi_width))]
                            df_locs = df_locs[(df_locs.y > (img_size/2-roi_width))
                                              & (df_locs.y < (img_size/2+roi_width))]
                        df_locs = df_locs[df_locs.t <= 500]
                        quick = '_quick'
                    else:
                        quick = ''
            
                    if roi_boolean:
                        # Look for ROI paths
                        pathsROI = natsorted(glob(os.path.dirname(path) + '/*.roi', recursive=False))
                        print(f'Adding {len(pathsROI)} ROI infos.')
            
                        dict_roi = {'cell_id': [], 'path': [], 'contour': [],
                                    'area': [], 'roi_mask': [], 'centroid': []}
                        # this stuff needs to go into tools
                        for idx, roi_path in enumerate(pathsROI):
                            roi_contour = tools.get_roi_contour(roi_path)
                            dict_roi['cell_id'].append(int(re.search(r'roi(\d+)\.roi$', roi_path).group(1)))
                            dict_roi['path'].append(roi_path)
                            dict_roi['contour'].append(roi_contour)
                            dict_roi['area'].append(tools.get_roi_area(roi_contour))
                            dict_roi['roi_mask'].append(
                                tools.get_roi_mask(df_locs, roi_contour))
                            dict_roi['centroid'].append(
                                tools.get_roi_centroid(roi_contour))
            
                        df_roi = pd.DataFrame(dict_roi)
            ################################################################################################
            #         # save ('quick'-cropped) locs in nm and plot stats
                    px2nm = self.settings.get_px2nm(resultPath)
                    df_locs_nm = tools.df_convert2nm(df_locs, px2nm)
                    path_nm = os.path.splitext(path)[0]+quick+self.settings.link_settings.suffix+'_nm.csv'
                    df_locs_nm.to_csv(path_nm, index=False)
                    path_plots_loc = tools.getOutputpath(path_nm, 'plots', keepFilename=True)
            
                    # tau_bleach = plot_diffusion.plot_loc_stats(df_locs_nm, path_plots_loc, dt=dt)
            
                    # prepare rest of the paths
                    path_output = os.path.splitext(path_nm)[0] +'_'+ self.settings.link_settings.tracker
                    path_plots = tools.getOutputpath(path_nm, 'plots', keepFilename=True) +'_'+ self.settings.link_settings.tracker
            
                    # Choose tracking algorithmus
                    if self.settings.link_settings.tracker == 'trackpy':
                        # print('Using trackpy.\n')
                        # export parameters to yaml
                        with open(os.path.splitext(path_nm)[0] +'_'+ self.settings.link_settings.tracker+ '.yaml', 'w') as f:
                            yaml.dump(vars(self.settings.link_settings), f)
                        
                        tracks_list = []
                        next_track_id = 0  # global track counter
                        
                        for cid, group in df_locs.groupby("cell_id"):
                            group_sorted = group.sort_values("t")  # ensure t is increasing
                            linked = link.link_locs_trackpy(
                                group_sorted,
                                search=self.settings.link_settings.search, 
                                memory=self.settings.link_settings.memory
                            )
                        
                            # offset track IDs to make them globally unique
                            if not linked.empty:
                                linked["track.id"] += next_track_id
                                next_track_id = linked["track.id"].max() + 1
                        
                            linked["cell_id"] = cid
                            tracks_list.append(linked)
                        
                        df_tracksTP = pd.concat(tracks_list, ignore_index=True)
                        
                        
                        # df_tracksTP = link.link_locs_trackpy(df_locs, search=self.settings.link_settings.search, memory=self.settings.link_settings.memory)
            
                        # # linked file is saved with pixel-corrected coordinates and
                        # # swiftGUI compatible columns, and unique track.ids
                        df_tracks = tools.df_convert2nm(df_tracksTP, px2nm)
                        df_tracks['seg.id'] = df_tracksTP['track.id']
                        if 'roi' in path:
                            df_tracks = tools.get_unique_trackIDs(df_tracks)
                        df_tracks.to_csv(path_output + '.csv', index=False)
                        ch = path_output.split('\\')[-1].split('_')[1]
                    #If I ever adapt it, swift goes here:
                    
            
            #         # Analysis and Plotting
            
                    print('Calculating and plotting particle-wise diffusion analysis...\n')
                    df_stats = link.get_particle_stats(df_tracks,
                                                       dt=dt,
                                                       particle='track.id',
                                                       t='t')
            
            #         # adding ROI stats to track stat file
                    if roi_boolean:
                        df_stats = df_stats.merge(
                            df_roi[['path', 'contour', 'area', 'centroid', 'cell_id']], on='cell_id', how='left')
                    # Save dataframe with track statistics (unfiltered)
                    if os.path.isfile(path_output + '_stats.hdf'):
                        os.remove(path_output + '_stats.hdf')  # force overwriting
                    df_stats.to_hdf(path_output + '_stats.hdf',
                                    key='df_stats', mode='w')
                    
                    if self.settings.link_settings.coloc:
                        self.tracks_coloc[ch] = df_tracks
                        self.tracks_coloc_stats[ch] = df_stats
                    else:
                        self.tracks[ch] = df_tracks
                        self.tracks_stats[ch] = df_stats
                    
                # Filter short tracks and immobile particles
                    if not self.settings.link_settings.coloc:
                        df_statsF = link.filter_df(df_stats, filter_length=self.settings.link_settings.fil_len, filter_D=self.settings.link_settings.fil_diff)
                        plot_diffusion.plot_track_stats(df_tracks, df_stats, df_statsF, path_plots, dt=dt, px2nm = px2nm)
                except Exception as e:
                    print(f"Error processing {path}: {e}")
                    print('I do not think you have many tracks... OR self.search is too large')
                    skippedPaths.append(path)
                    continue
        except Exception as e:
            print('Error')
        print('--------------------------------------------------------')
        print('/////////////////////FINISHED//////////////////////////')
        print('--------------------------------------------------------')
        if skippedPaths:
            print('Analysis failed on paths:')
            for skippedPath in skippedPaths:
                print(f'\n{skippedPath}')
    def coloc_tracks(self):
        """
        Identify colocalized particle trajectories between two channels.

        Compares trajectories in channel `ch0` and `ch1` to find temporally overlapping
        tracks within a defined spatial threshold (bounding box of the track in ch0 plus a few pixels) and 
        minimum shared frame count.

        Steps:
        - Load per-channel `*_trackpy.csv` files.
        - Compute frame-by-frame overlap and distance thresholds.
        - Save colocalized tracks (`*_colocsTracks.csv`) and stats (`*_colocsTracks_stats.hdf`).
        - Optionally merge ROI information if available.

        Raises
        ------
        FileNotFoundError
            If the second channel (`ch1`) is not specified or files are missing.
        """
        settings = self.settings.coloc_tracks_settings
        # format paths according to a specified ending, e.g. "488nm_locs.csv"
        ch0 = settings.ch0
        ch1 = settings.ch1

        # getting all filenames of the first channel, later look for corresponding second channel files
        if os.path.isdir(self.image_folder):
            print('Analyzing directory...')
            pathsCh0 = glob(self.image_folder + f'//**//*{ch0}*_locs_nm_trackpy.csv', recursive=True)
            print(f'Found {len(pathsCh0)} files for channel 0...')
            # for path in pathsCh0:
            #     print(path)
        else:
            raise FileNotFoundError('Directory not found')
        print('--------------------------------------------------------')
        skippedPaths = []
        # main loop
        for idx, pathCh0 in tqdm(enumerate(pathsCh0), desc='Looking for colocalizations...'):
            print(pathCh0)
            try:
                dirname = os.path.dirname(pathCh0)
                if ch1 == None:
                    raise FileNotFoundError('Second channel not declared.')
                    print('--------------------------------------------------------')
                else:
                    pathCh1 = glob(dirname + f'/**{ch1}*_locs_nm_trackpy.csv')[idx]
                    # read in the linked files
                    df_locs_ch0 = pd.read_csv(pathCh0)
                    df_locs_ch1 = pd.read_csv(pathCh1)
                    # pixels to nm

        #             # get colocalizations
                    df_colocs, coloc_stats = coloc.coloc_tracks(df_locs_ch0, df_locs_ch1,leng = settings.min_len_track, max_distance=settings.th, n = settings.min_overlapped_frames)
                        
        #             # get right output paths
                    pathOutput = os.path.splitext(pathCh0)[0][:] + settings.suffix

                    print('Saving colocalizations...')
                    df_colocs.to_csv(pathOutput + '_colocsTracks.csv', index=False)
                    if 'roi' in pathCh0:
                        # Look for ROI paths
                        pathsROI = natsorted(glob(os.path.dirname(pathCh0) +
                                        '/*.roi', recursive=False))
                        print(f'Adding {len(pathsROI)} ROI infos.')
            
                        dict_roi = {'cell_id': [], 'path': [], 'contour': [],
                                    'area': [], 'centroid': []}
                        # this stuff needs to go into tools
                        for idx, roi_path in enumerate(pathsROI):
                            roi_contour = tools.get_roi_contour(roi_path)
                            dict_roi['cell_id'].append(int(re.search(r'roi(\d+)\.roi$', roi_path).group(1)))
                            dict_roi['path'].append(roi_path)
                            dict_roi['contour'].append(roi_contour)
                            dict_roi['area'].append(tools.get_roi_area(roi_contour))
                            dict_roi['centroid'].append(
                                tools.get_roi_centroid(roi_contour))
            
                        df_roi = pd.DataFrame(dict_roi)
                        coloc_stats = coloc_stats.merge(
                            df_roi[['path', 'contour', 'area', 'centroid', 'cell_id']], on='cell_id', how='left')

                    info_file = "\\".join(pathCh0.split('\\')[:-1]) +"\\"+ pathCh0.split('\\')[-1].split('.')[0]+'.yaml'
                    # export parameters to yaml
                    infoNew = tools.load_info(info_file)
                    infoNew.append(vars(settings))
                    
                    save_info(pathOutput + '_colocsTracks.yaml', infoNew)
                    
                    if os.path.isfile(pathOutput + '_colocsTracks_stats.hdf'):
                        os.remove(pathOutput + '_colocsTracks_stats.hdf')  # force overwriting
                    coloc_stats.to_hdf(pathOutput + '_colocsTracks_stats.hdf',
                                    key='df_stats', mode='w')
                    self.coloc_tracks = df_colocs
                    self.coloc_tracks_stats = coloc_stats
            except Exception:
                skippedPaths.append(pathCh0)
                print('--------------------------------------------------------')
                print(f'Path {pathCh0} could not be analyzed. Skipping...\n')
                traceback.print_exc()

            

        print('                                                        ')

        print('--------------------------------------------------------')
        print('/////////////////////FINISHED//////////////////////////')
        print('--------------------------------------------------------')
        if skippedPaths:
            print('Skipped paths:')
            for skippedPath in skippedPaths:
                print(f'\n{skippedPath}\n')
    def coloc_spots(self):
        """
        Identify colocalized spots (single-frame events) between two channels.

        Unlike `coloc_tracks`, this method detects colocalization on a per-frame basis
        between two localization tables (e.g., `488nm_locs.csv` and `638nm_locs.csv`).

        Steps:
        - Load localization CSVs for `ch0` and `ch1`.
        - Convert pixel coordinates to nanometers.
        - Identify colocalized events within the distance threshold `th`.
        - Save results as `*_colocs.csv` and generate summary plots.

        Raises
        ------
        FileNotFoundError
            If corresponding channel files cannot be located.
        """
        settings = self.settings.coloc_spots_settings
        # format paths according to a specified ending, e.g. "488nm_locs.csv"
        ch0 = settings.ch0
        ch1 = settings.ch1
        # getting all filenames of the first channel, later look for corresponding second channel files
        if os.path.isdir(self.image_folder):
            print('Analyzing directory...')
            pathsCh0 = glob(self.image_folder + f'//**//*{ch0}*_locs.csv', recursive=True)
            print(f'Found {len(pathsCh0)} files for channel 0...')
            # for path in pathsCh0:
            #     print(path)
        else:
            raise FileNotFoundError('Directory not found')
        print('--------------------------------------------------------')
        skippedPaths = []
        # main loop
        for idx, pathCh0 in tqdm(enumerate(pathsCh0), desc='Looking for colocalizations...'):
            print(pathCh0)
            try:
                dirname = os.path.dirname(pathCh0)
                if ch1 == None:
                    raise FileNotFoundError('Second channel not declared.')
                    print('--------------------------------------------------------')
                else:
                    pathCh1 = glob(dirname + f'/**{ch1}*_locs.csv')[idx]
                    # print(f'\nFound a second channel for file {idx}.')
                    resultPath  = '\\'.join(pathCh0.split('\\')[:-1]) + '\\' + [element for element in pathCh0.split('\\') if element.startswith('Run')][0] + '_result.txt'
                    if not settings.dt == None:
                        dt = settings.dt
                    else:
                        resultTxt = open(resultPath, 'r')
                        resultLines = resultTxt.readlines()
                        if tools.find_string(resultLines, 'Interval'): 
                            interval = tools.find_string(resultLines, 'Interval').split(":")[-1].strip()
                            if interval.split(" ")[-1] == 'sec':
                                dt = int(float(interval.split(" ")[0]))
                            elif interval.split(" ")[-1] == 'ms':
                                dt = 0.001 * int(float(interval.split(" ")[0]))
                        else:
                            dtStr = tools.find_string(
                                resultLines, 'Camera Exposure')[17:-1]
                            dt = 0.001 * int(float((''.join(c for c in dtStr if (c.isdigit() or c == '.')))))

                    # read in the linked files
                    df_locs_ch0 = pd.read_csv(pathCh0)
                    df_locs_ch1 = pd.read_csv(pathCh1)
                    # pixels to nm
                    px2nm = self.settings.get_px2nm(pathCh0)
                    df_locs_ch0 = tools.df_convert2nm(df_locs_ch0, px2nm)
                    df_locs_ch1 = tools.df_convert2nm(df_locs_ch1, px2nm)

        #             # get colocalizations
                    df_colocs = coloc.colocalize_from_locs(df_locs_ch0, df_locs_ch1, threshold_dist=settings.th)

        #             # get right output paths
                    pathOutput = os.path.splitext(pathCh0)[0][:-5] + settings.suffix
                    pathPlots = tools.getOutputpath(pathCh0, 'plots', keepFilename=True)[:-9] + settings.suffix

                    print('Saving colocalizations...')
                    df_colocs_px = tools.df_convert2px(df_colocs, px2nm)
                    df_colocs_px.to_csv(pathOutput + '_colocs.csv', index=False)
                    print('Calculating and plotting colocalization analysis.')
                    if not df_colocs.empty:
                        plot_coloc.plot_coloc_stats(df_locs_ch0, df_locs_ch1, df_colocs,
                                                    threshold=settings.th,
                                                    path=pathPlots, dt=dt, roll_param=5)
                    info_file = "\\".join(pathCh0.split('\\')[:-1]) +"\\"+ pathCh0.split('\\')[-1].split('.')[0]+'.yaml'
                    # export parameters to yaml
                    infoNew = tools.load_info(info_file)
                    infoNew.append(vars(settings))
                    
                    save_info(pathOutput + '_colocs.yaml', infoNew)
                    self.coloc_spots = df_colocs_px

            except Exception:
                skippedPaths.append(pathCh0)
                print('--------------------------------------------------------')
                print(f'Path {pathCh0} could not be analyzed. Skipping...\n')
                traceback.print_exc()

            

        print('                                                        ')

        print('--------------------------------------------------------')
        print('/////////////////////FINISHED//////////////////////////')
        print('--------------------------------------------------------')
        if skippedPaths:
            print('Skipped paths:')
            for skippedPath in skippedPaths:
                print(f'\n{skippedPath}\n')
    def full_analysis_noROI(self, mode = 'tracks'):
        """
       Execute a full automated pipeline (without ROIs).

       Runs the complete SPIT analysis workflow for the current dataset:
       affine transform → localization → linking → colocalization.

       Parameters
       ----------
       mode : {'tracks', 'spots'}, default='tracks'
           Analysis mode. Choose between:
           - 'tracks': performs trajectory linking and track colocalization.
           - 'spots': performs spot-based colocalization.
       """
        original_roi = self.settings.link_settings.roi
        self.settings.link_settings.roi = False
        self.table()
        self.affine_transform()
        self.localize()
        if mode == 'tracks':
            original_coloc = self.settings.link_settings.coloc
            if original_coloc:
                print('LinkingSettings - coloc was True, changing to False for mode = "Tracks"')
                self.settings.link_settings.coloc = False
            self.link()
            self.coloc_tracks()
            if original_coloc:
                self.settings.link_settings.coloc = original_coloc
        elif mode == 'spots':
            self.coloc_spots()
            self.settings.link_settings.coloc = False
            self.link()
            self.settings.link_settings.coloc = True
            self.link()
        self.settings.link_settings.roi = original_roi
    def full_analysis_ROI(self, mode = 'tracks'):
        """
       Execute a full pipeline including ROI restriction.

       Runs the full workflow for datasets that include manually drawn ROIs:
       First, affine transform must be run manually and ROIs must be generated in imageJ
       Then, this functions automatically runs:
       ROI → localization → linking → colocalization.

       Parameters
       ----------
       mode : {'tracks', 'spots'}, default='tracks'
           Type of analysis to perform.
       """
        pathsROI = natsorted(glob(self.image_folder + '/*.roi', recursive=False))
        if not pathsROI:
            print('Be aware that for this mode you first need to do the .affine_transform and then manually draw ROIs with imageJ freehand tool, and save them as roiX.roi where X is a number starting by 0 and going up to as many ROIs there are')
        else:
            original_roi = self.settings.link_settings.roi
            self.settings.link_settings.roi = True
            self.table()
            self.localize()
            self.roi()
            if mode == 'tracks':
                self.link()
                self.coloc_tracks()
            elif mode == 'spots':
                self.coloc_spots()
                self.settings.link_settings.coloc = False
                self.link()
                self.settings.link_settings.coloc = True
                self.link()
            self.settings.link_settings.roi = original_roi
    def table(self):
        """
        Generate a summary table for the run to generate an overview of experimental metadata and processing outcomes.
        """
        table.createTable(self.folder)
    def _find_alternative_result_file(self, folder):
        """
        Search for result and datalog files in sibling directories.

        If the current folder is missing its `*_result.txt` and `*_datalog.txt` files,
        this method looks one directory level up for sibling folders that contain
        both files.

        Parameters
        ----------
        folder : str
            Path to the current experiment folder.

        Returns
        -------
        tuple of str
            Paths to the fallback result and datalog files.

        Raises
        ------
        FileNotFoundError
            If no valid fallback files are found.
        """
        parent = os.path.dirname(folder)

        # Look for all *_result.txt files one level down from the parent directory
        result_files = glob(os.path.join(parent, '*', '*_result.txt'))

        for result_file in result_files:
            sib_folder = os.path.dirname(result_file)
            base = os.path.basename(sib_folder)
            datalog_file = os.path.join(sib_folder, base + '_datalog.txt')
            
            if os.path.exists(datalog_file):
                print(f"[Fallback] Found result files in: {sib_folder} for {folder}")
                return result_file, datalog_file

        raise FileNotFoundError("No valid *_result.txt found within the same parent folder. Copy one yourself.")
class SPIT_Dataset:
    """
    SPIT_Dataset
    ============

    A batch-processing controller for running SPIT analysis across multiple experiment 
    subfolders within a dataset directory.

    The `SPIT_Dataset` class automates the sequential execution of the full SPIT
    pipeline—affine correction, localization, ROI restriction, linking, and colocalization—
    across all detected experiment runs (each identified by a `.raw` file and its parent folder).

    Each detected subfolder is processed by initializing a `SPIT_Run` instance,
    which handles the per-experiment operations.

    Attributes
    ----------
    folder : str
        Path to the root dataset folder containing multiple experiment subdirectories.
    settings : object
        A user-defined settings object with all experiment parameters.
    output_folder : str
        Path to the shared output folder for processed data. Automatically created as `<folder>/output`.

    Methods
    -------
    affine_transform():
        Applies affine registration correction to all runs in the dataset.
    localize():
        Detects and fits fluorescence spots for all runs.
    roi():
        Restricts localizations to user-defined ROIs across all runs.
    link():
        Links localizations into trajectories for all runs.
    coloc_tracks():
        Performs colocalization analysis on trajectories between channels.
    coloc_spots():
        Performs spot-based colocalization analysis between channels.
    SPIT_noROI(mode='tracks'):
        Runs the full automated pipeline (without ROI filtering) for all runs.
    SPIT_ROI(mode='tracks'):
        Runs the full pipeline including ROI restriction for all runs.
    table():
        Generates a summary table for the entire dataset.

    Examples
    --------
    >>> dataset = SPIT_Dataset(r"C:\\Data\\Experiment_Set_01", settings)
    >>> dataset.affine_transform()
    >>> dataset.localize()
    >>> dataset.link()
    >>> dataset.coloc_tracks()

    Or to perform the full analysis in one step:
    >>> dataset.SPIT_noROI(mode='tracks')
    """
    def __init__(self, folder, settings):
        self.folder = folder
        self.settings = settings
        self.output_folder = os.path.join(folder, 'output')
    def affine_transform(self):
        """
        Perform affine registration corrections for all experiment subfolders.

        This method recursively scans the dataset folder for `.raw` files, identifies
        their parent directories, and applies affine transformations to each one via
        `SPIT_Run.affine_transform()`.
        """
        directory_path = self.folder
        pathsRaw = glob(directory_path + '/**/**.raw', recursive=True) #Check for each .row file in the folder and subfolders. 
        directory_names = list(set(os.path.dirname(file) for file in pathsRaw)) #makes a lost with the direction to each folder containing .raw files. 
        for path in directory_names:
            if os.path.isdir(path):
                # if "cont" in path:
                    to_process = SPIT_Run(path, self.settings, directory_path)
                    to_process.affine_transform()
        print('########Finished########')
    def localize(self):
        """
        Perform spot localization across all experiment subfolders.

        Detects and fits fluorescent spots in each experiment folder using
        `SPIT_Run.localize()`.

        """
        directory_path = self.folder
        pathsRaw = glob(directory_path + '/**/**.raw', recursive=True) #Check for each .row file in the folder and subfolders. 
        directory_names = list(set(os.path.dirname(file) for file in pathsRaw)) #makes a lost with the direction to each folder containing .raw files. 
        for path in directory_names:
            if os.path.isdir(path):
                # if "cont" in path:
                    to_process = SPIT_Run(path, self.settings, directory_path)
                    to_process.localize()
        print('########Finished########')
    def roi(self):
        """
       Restrict localizations to user-defined ROIs for all experiments.

       Loads ROI files (from ImageJ/Fiji `.roi` format) and filters localizations
       using `SPIT_Run.roi()`.
      
       Notes
       -----
       - The method can be adapted to skip already processed ROIs (see commented code).
       """
        directory_path = self.folder
        pathsRaw = glob(directory_path + '/**/**.raw', recursive=True) #Check for each .row file in the folder and subfolders. 
        directory_names = list(set(os.path.dirname(file) for file in pathsRaw)) #makes a lost with the direction to each folder containing .raw files. 
        for path in directory_names:
            if os.path.isdir(path):
                to_process = SPIT_Run(path, self.settings, directory_path)
                # if "cont" in path:
                # if any('roi_locs.csv' in fname for fname in os.listdir(to_process.image_folder)):
                #     print(f'skipped {path}')
                #     continue  # Skip roi() if such a file exists
                to_process.roi()

        print('########Finished########')
    def link(self):
        """
       Link localizations into trajectories across all experiments.

       Runs `SPIT_Run.link()` for each subfolder, forming trajectories
       based on proximity and temporal continuity.
       """
        directory_path = self.folder
        pathsRaw = glob(directory_path + '/**/**.raw', recursive=True) #Check for each .row file in the folder and subfolders. 
        directory_names = list(set(os.path.dirname(file) for file in pathsRaw)) #makes a lost with the direction to each folder containing .raw files. 
        for path in directory_names:
            if os.path.isdir(path):
                to_process = SPIT_Run(path, self.settings, directory_path)
                to_process.link()
        print('########Finished########')
    def coloc_tracks(self):
        """
        Perform trajectory-based colocalization across all experiments.

        For each experiment subfolder, this method calls `SPIT_Run.coloc_tracks()`
        to find overlapping particle trajectories between fluorescence channels.

        """
        directory_path = self.folder
        pathsRaw = glob(directory_path + '/**/**.raw', recursive=True) #Check for each .row file in the folder and subfolders. 
        directory_names = list(set(os.path.dirname(file) for file in pathsRaw)) #makes a lost with the direction to each folder containing .raw files. 
        for path in directory_names:
            if os.path.isdir(path):
                to_process = SPIT_Run(path, self.settings, directory_path)
                to_process.coloc_tracks()
        print('########Finished########')
    def coloc_spots(self):
        """
        Perform single-frame (spot-level) colocalization across all experiments.

        Detects colocalized fluorescent events between channels for each
        experiment using `SPIT_Run.coloc_spots()`.
        """
        directory_path = self.folder
        pathsRaw = glob(directory_path + '/**/**.raw', recursive=True) #Check for each .row file in the folder and subfolders. 
        directory_names = list(set(os.path.dirname(file) for file in pathsRaw)) #makes a lost with the direction to each folder containing .raw files. 
        for path in directory_names:
            if os.path.isdir(path):
                print(path)
                to_process = SPIT_Run(path, self.settings, directory_path)
                to_process.coloc_spots()
        print('########Finished########')
    def SPIT_noROI(self, mode = 'tracks'):
        """
        Execute a full automated SPIT pipeline for all experiments (no ROI filtering).

        Runs the complete sequence:
        affine transform → localization → linking → colocalization
        via `SPIT_Run.full_analysis_noROI()` for each subfolder.

        Parameters
        ----------
        mode : {'tracks', 'spots'}, default='tracks'
            Choose between:
            - 'tracks': trajectory-level analysis.
            - 'spots': single-frame colocalization.
        """
        directory_path = self.folder
        pathsRaw = glob(directory_path + '/**/**.raw', recursive=True) #Check for each .row file in the folder and subfolders. 
        directory_names = list(set(os.path.dirname(file) for file in pathsRaw)) #makes a lost with the direction to each folder containing .raw files. 
        for path in directory_names:
            if os.path.isdir(path):
                to_process = SPIT_Run(path, self.settings, directory_path)
                to_process.full_analysis_noROI(mode = mode)
        print('########Finished########')
    def SPIT_ROI(self, mode = 'tracks'):
        """
       Execute the full SPIT pipeline including ROI filtering for all experiments.
       
       Affine_transform and roi generation must be done beforehand. Runs localization, ROI restriction, linking, 
       and colocalization using `SPIT_Run.full_analysis_ROI()` for each detected subfolder.

       Parameters
       ----------
       mode : {'tracks', 'spots'}, default='tracks'
           Choose between trajectory- or spot-based colocalization.

       """
        directory_path = self.folder
        pathsRaw = glob(directory_path + '/**/**.raw', recursive=True) #Check for each .row file in the folder and subfolders. 
        directory_names = list(set(os.path.dirname(file) for file in pathsRaw)) #makes a lost with the direction to each folder containing .raw files. 
        for path in directory_names:
            if os.path.isdir(path):
                print(f"Analyszing {path}")
                to_process = SPIT_Run(path, self.settings, directory_path)
                to_process.full_analysis_ROI(mode = mode)
        print('########Finished########')
    def table(self):
        """
        Generate a summary table for the entire dataset.

        Calls `table.createTable()` on the dataset folder to produce a comprehensive
        overview of experimental results, including all runs and associated metrics.
        """
        table.createTable(self.folder)
        print('########Finished########')

class localize_tiff_run:
    """
    Handles affine transformation, localization, ROI filtering, and colocalization
    of single frame TIFF microscopy multi-channel images.

    Attributes
    ----------
    folder : str
        Path to the folder containing TIFF image data.
    settings : object
        Configuration object with parameters for registration, localization, and colocalization.
    output_folder : str
        Path to the directory where processed data is saved.
    image_folder : str
        Path for intermediate output files (typically '<output_folder>/output/...').

    Methods
    -------
    affine_transform()
        Applies affine transformations and channel-specific cropping to raw TIFF images.
    localize()
        Detects and fits fluorescent spots in TIFF images.
    roi()
        Restricts localizations to manually drawn ROIs (Regions of Interest).
    colocalize()
        Performs colocalization analysis between channels.
    full_analysis_noROI(mode='tracks')
        Runs the complete pipeline (affine transform → localize → colocalize)
        without ROI filtering.
    full_analysis_ROI(mode='tracks')
        Runs the complete pipeline with ROI-based localization and colocalization.
    _load_tif(file)
        Loads a TIFF file and returns its image data as a numpy array.
    _h_affine_transform(image, H)
        Applies an affine transformation to an image using matrix H.
    """
    def __init__(self, folder, settings, output_folder = None):
        self.folder = folder
        self.settings = settings
        if output_folder is None:
            self.output_folder = folder
        else:
            self.output_folder = output_folder
        self.image_folder = os.path.join(self.output_folder, 'output', self.folder.replace(self.output_folder, '')[1:])
    def affine_transform(self):
        """
       Perform affine transformations and cropping on all TIFF images in the folder.

       This method:
       1. Loads microscope-specific calibration matrices and crop coordinates.
       2. Applies affine transformations to each channel.
       3. Crops and saves the corrected images as new TIFF files.

       """
        settings2 = self.settings.registration_settings
        # registration_folder  = settings2.registration_folder
        verticalROI = settings2.verticalROI
        if not os.path.exists(self.image_folder): #create the save folder if it does not exist. 
            os.makedirs(self.image_folder)
        #check whether Annapurna or K2 was used and initialize the neceesary variables depening on that
        if settings2.microscope == 'ANNAPURNA': 
            x_coords = settings2.x_coords_annapurna_tiff
            Hl  = self.settings.load_H_left_annapurna()
            Hr = self.settings.load_H_right_annapurna()
            xlim, ylim = self.settings.load_crop_annapurna()
        elif settings2.microscope == 'K2':
            x_coords = settings2.x_coords_K2_tiff
            Hl  = self.settings.load_H_left_K2()
            Hr = self.settings.load_H_right_K2()
            xlim, ylim = self.settings.load_crop_K2()
        #check the imaging mode used: sequence or record (a.k.a VCR). 
        pattern = settings2.channels #get the lasers that you used. 
        file_names =  glob(self.folder + '/**/**.tif', recursive=True)#open the raw file
        for file_name in file_names:
            d = self._load_tif(file_name)
            for ch in pattern: #for each laser used
                image = np.copy(d[verticalROI[0]:verticalROI[1], x_coords[ch][0]:x_coords[ch][1]]) #crop the specific channel
                if ch == 'r_ch':#if the laser used is 405 or 488, use the right H matrix to correct. 
                    im = self._h_affine_transform(image, Hr)
                elif ch == 'l_ch':#if the laser used is the 638. used the left H matrix to correct. 
                    im = self._h_affine_transform(image, Hl)
                elif ch == 'm_ch':#If none of them have been used (561 laser has been used), do not modify the image
                    im = np.copy(image)
                cropped_im  = im[ylim[0]:ylim[1], xlim[0]:xlim[1]].astype(np.uint16) #crop the image in the proper cropping coordinates (after the correction). 
                save = os.path.join(self.image_folder, file_name.split('\\')[-1].split('.')[0]+'_'+ch+'.tif') #save the image as .tif
                imageio.mimwrite(save, [cropped_im])
        
        print('########Finished########')
    def localize(self):
        """
        Localize fluorescent spots in TIFF images using specified fitting methods.

        Steps
        -----
        1. Scans the output directory for TIFF files.
        2. Computes gradients and identifies candidate spots.
        3. Fits detected spots using the chosen fit method ('lq' or 'com').
        4. Applies non-affine transformations if enabled in settings.
        5. Saves localization results as CSV and metadata as YAML.

        Outputs
        -------
        - `<image>_locs.csv`: localized spot coordinates and intensity values.
        - `<image>.yaml`: metadata including gradient and fit method.

        """
        transformInfo = 'False' 
        #Actually not needed, because you can only add folders, based on a function in def main: 
        if os.path.isdir(self.image_folder): 
           print('Analyzing directory', self.image_folder)
           pathsTif = glob(self.image_folder + '/*.tif', recursive=True)
           paths = pathsTif
        # subdirectories = list({os.path.dirname(file_path) for file_path in paths})
           print(f'A total of {len(paths)} files detected...')
           print('--------------------------------------------------------')
        else:
            print(f'{self.image_folder} is not a folder')
            
        # If any of the folders does not contain tif or raw images, it will be skipped and the folder will be saved in the following list:
        skippedPaths = []  
        if paths: 
            movieList = []
            filelist = []
            for i, path in enumerate(paths):
                filelist.append(path)
                movie, info = load_movie(path)
                movieList.append(movie)
                area = info[0]['Width']*info[0]['Height']*self.settings.get_px2um_tiffs()*self.settings.get_px2um_tiffs()
                gradient = self.settings.gradient_tiffs(path)
                print(path)
                print(f'Localizing file {path}')
                print('--------------------------------------------------------')
                print('gradient:', self.settings.gradient_tiffs(path))
                
                #Localize spots in the images based on the chosen fit-method
                current, futures = identify_async(movie, gradient, self.settings.localization_settings.box)
                ids = identifications_from_futures(futures)     
                box = self.settings.localization_settings.box
                camera_info = self.settings.localization_settings.camera_info
                if self.settings.localization_settings.fit_method == 'lq':
                    spots = get_spots(movie, ids, box, camera_info)
                    theta = gausslq.fit_spots_parallel(spots, asynch=False)
                    locs = gausslq.locs_from_fits(ids, theta, box, camera_info['Gain'])
                elif self.settings.localization_settings.fit_method == 'com':
                    spots = get_spots(movie, ids, box,camera_info)
                    theta = avgroi.fit_spots_parallel(spots, asynch=False)
                    locs = avgroi.locs_from_fits(ids, theta, box, camera_info['Gain'])
                else:
                    print('This should never happen... Please, set a proper method: com for moving particles, lq for moving stuff')
                #save the localizations in a dataframe        
                df_locs = pd.DataFrame(locs)
                # Compatibility with Swift
                df_locs = df_locs.rename(columns={'frame': 't', 'photons': 'intensity'})
    
                # adding localization precision, nearest neighbor, change photons, add cell_id column
                df_locs['loc_precision'] = df_locs[['lpx', 'lpy']].mean(axis=1)
                df_locs['cell_id'] = 0

                # Non-affine correction only makes sense if we are dealing with two/three channel data. If you do not have these or want to update them, 
                #use get_non-affine_coefs.py. 
                if self.settings.localization_settings.transform:
                    #open non-affine coefficients. 
                    naclibCoefficients = self.settings.get_naclib_tiffs(path)
                    #transform localizations based on the coefficients assigned to channel 2 (488nm or 405nm channel)
                    if '488nm' in path or '405nm' in path:
                        df_locs, dataset = localize.transform_locs(df_locs,
                                                                   naclibCoefficients,
                                                                   channel=2,
                                                                   fig_size=list(movie[0].shape[::-1]))
                        transformInfo = 'true, based on '+str(dataset)
                   #transform localizations based on the coefficients assigned to channel 0 (638nm channel)
                    elif '638nm' in path:
                        df_locs, dataset = localize.transform_locs(df_locs,
                                                                   naclibCoefficients,
                                                                   channel=0,
                                                                   fig_size=list(movie[0].shape[::-1]))
                        transformInfo = 'true, based on '+str(dataset)
                    #do not modify 531nm channel, since it is the reference channel.
                    else:
                        transformInfo = 'false, reference channel'
               #update info (.yaml)            
                localize_info = {
                    'Generated by': 'Picasso Localize',
                    'Box Size': self.settings.localization_settings.box,
                    'Min. Net Gradient': gradient,
                    'Color correction': transformInfo,
                    'Area': float(area),
                    'Fit method': self.settings.localization_settings.fit_method
                }
                info[0]["Byte Order"] = "<" #I manually checked with https://hexed.it/ that the tif files are still saved as little-endian
                infoNew = info.copy()
                infoNew.append(localize_info)
                #get saving folder
                base, ext = os.path.splitext(path)
     
                pathChannel = base
    
                pathOutput = pathChannel + self.settings.localization_settings.suffix + '_locs.csv'
                #save localizations and ifnromation
                df_locs.to_csv(pathOutput, index=False)
                save_info(os.path.splitext(pathOutput)[0]+'.yaml', infoNew)
        
                print(f'File saved to {pathOutput}')
                print('                                                        ')
        else: 
           # "There are no files in this subfolder, rise error"
           skippedPaths.append(self.folder)
           print('Skipping...\n')
           print('--------------------------------------------------------')
    def roi(self):
        """
        Restrict localization results to user-defined ROIs.

        Steps
        -----
        1. Loads all localization files (`*ch_locs.csv`) from the output directory.
        2. Reads ROI definitions (`roiX.roi`) drawn in ImageJ.
        3. Computes ROI masks, centroids, and areas.
        4. Filters localizations to those within ROI boundaries.
        5. Saves filtered results to `<image>_roi_locs.csv` and updates metadata.

        Notes
        -----
        - Requires `.roi` files in the same directory.
        - ROIs must be named as `roi0.roi`, `roi1.roi`, etc.
        """

        # format filepaths
        if os.path.isdir(self.image_folder):
            print('Analyzing directory...')
            paths = glob(self.image_folder + '/*ch_locs.csv')

        # initialize placeholders
        skippedPaths = []

        # print all kept paths
        for path in paths:
            print(path)
        print(f'A total of {len(paths)} files detected...')
        print('--------------------------------------------------------')
        self.locs_roi = {}
        # main loop
        for idx, path in tqdm(enumerate(paths), desc='Saving new loc-files...', total=len(paths)):
            print('--------------------------------------------------------')
            print(f'Running file {path}')
            try:
                (df_locs, info) = tools.load_locs(path)
                # Look for ROI paths
                pathsROI = natsorted(glob(os.path.dirname(path) + '/*.roi', recursive=False))
                print(f'Found {len(pathsROI)} ROI.')

                dict_roi = {'cell_id': [], 'path': [], 'contour': [],
                            'area': [], 'roi_mask': [], 'centroid': []}
                
                # this stuff needs to go into tools
                df_locs = df_locs.drop('cell_id', axis=1)
                for idx, roi_path in enumerate(pathsROI):
                    roi_contour = tools.get_roi_contour(roi_path)
                    dict_roi['cell_id'].append(int(re.search(r'roi(\d+)\.roi$', roi_path).group(1)))
                    dict_roi['path'].append(roi_path)
                    dict_roi['contour'].append(roi_contour)
                    dict_roi['area'].append(tools.get_roi_area(roi_contour))
                    dict_roi['roi_mask'].append(
                        tools.get_roi_mask(df_locs, roi_contour))
                    dict_roi['centroid'].append(
                        tools.get_roi_centroid(roi_contour))

                df_roi = pd.DataFrame(dict_roi)
                df_locsM = pd.concat([df_locs[roi_mask] for roi_mask in df_roi.roi_mask], keys=list(
                    np.arange((df_roi.cell_id.size))))

                df_locsM.index = df_locsM.index.set_names(['cell_id', None])
                df_locsM = df_locsM.reset_index(level=0)
                df_locsM = df_locsM.sort_values(['cell_id', 't'])
                df_locsM = df_locsM.drop_duplicates(subset=['x', 'y'])  # if ROIs overlap
                df_locs = df_locsM
                # get right output paths
                pathOutput = path.replace('locs.csv', 'roi_locs.csv')
                df_locs.to_csv(pathOutput, index=False)
                ch = pathOutput.split('\\')[-1].split('_')[-3]
                self.locs_roi[ch] = df_locs
                roi_info = {'Cell ROIs': str(df_roi.cell_id.unique())}
                infoNew = info.copy()
                infoNew.append(roi_info)
                save_info(os.path.splitext(pathOutput)[0] + '.yaml', infoNew)
            except Exception:
                skippedPaths.append(path)

                print('--------------------------------------------------------')
                print(f'Path {path} could not be analyzed. Skipping...\n')
                traceback.print_exc()

        print('                                                        ')
        print('--------------------------------------------------------')
        print('/////////////////////FINISHED//////////////////////////')
        print('--------------------------------------------------------')
        if skippedPaths:
            print('Skipped paths:')
            for skippedPath in skippedPaths:
                print(f'\n{skippedPath}\n')
    def colocalize(self):
        """
       Perform colocalization analysis between two fluorescence channels.

       Steps
       -----
       1. Finds localization files for each specified channel (ch0 and ch1).
       2. Converts coordinates from pixels to nanometers.
       3. Computes colocalized points within a specified distance threshold.
       4. Saves results as CSV and metadata YAML files.

       Outputs
       -------
       - `<image>_colocs.csv`: colocalized coordinates.
       - `<image>_colocs.yaml`: YAML file with analysis parameters.

       """
        settings = self.settings.coloc_spots_settings
        # format paths according to a specified ending, e.g. "488nm_locs.csv"
        ch0 = settings.ch0_tiffs
        ch1 = settings.ch1_tiffs

        # getting all filenames of the first channel, later look for corresponding second channel files
        if os.path.isdir(self.image_folder):
            print('Analyzing directory...')
            pathsCh0 = glob(self.image_folder + f'//**//*{ch0}*_locs.csv', recursive=True)
            print(f'Found {len(pathsCh0)} files for channel 0...')
            # for path in pathsCh0:
            #     print(path)
        else:
            raise FileNotFoundError('Directory not found')
        print('--------------------------------------------------------')
        skippedPaths = []
        # main loop
        for idx, pathCh0 in tqdm(enumerate(pathsCh0), desc='Looking for colocalizations...'):
            print(pathCh0)
            try:
                dirname = os.path.dirname(pathCh0)
                if ch1 == None:
                    raise FileNotFoundError('Second channel not declared.')
                    print('--------------------------------------------------------')
                else:
                    pathCh1 = glob(dirname + f'/**{ch1}*_locs.csv')[idx]
                    # print(f'\nFound a second channel for file {idx}.')
                    print(pathCh0)
                    print(pathCh1)
                    # read in the linked files
                    df_locs_ch0 = pd.read_csv(pathCh0)
                    df_locs_ch1 = pd.read_csv(pathCh1)
                    # pixels to nm
                    px2nm = self.settings.get_px2nm_tiffs()
                    df_locs_ch0 = tools.df_convert2nm(df_locs_ch0, px2nm)
                    df_locs_ch1 = tools.df_convert2nm(df_locs_ch1, px2nm)

        #             # get colocalizations
                    df_colocs = coloc.colocalize_from_locs(df_locs_ch0, df_locs_ch1, threshold_dist=settings.th)

        #             # get right output paths
                    pathOutput = os.path.splitext(pathCh0)[0][:-5] + settings.suffix
                    # pathPlots = tools.getOutputpath(pathCh0, 'plots', keepFilename=True)[:-9] + settings.suffix

                    print('Saving colocalizations...')
                    df_colocs_px = tools.df_convert2px(df_colocs, px2nm)
                    df_colocs_px.to_csv(pathOutput + '_colocs.csv', index=False)
                    print('Calculating and plotting colocalization analysis.')

                    info_file = "\\".join(pathCh0.split('\\')[:-1]) +"\\"+ pathCh0.split('\\')[-1].split('.')[0]+'.yaml'
                    # export parameters to yaml
                    infoNew = tools.load_info(info_file)
                    infoNew.append(vars(settings))
                    
                    save_info(pathOutput + '_colocs.yaml', infoNew)

            except Exception:
                skippedPaths.append(pathCh0)
                print('--------------------------------------------------------')
                print(f'Path {pathCh0} could not be analyzed. Skipping...\n')
                traceback.print_exc()

            

        print('                                                        ')

        print('--------------------------------------------------------')
        print('/////////////////////FINISHED//////////////////////////')
        print('--------------------------------------------------------')
        if skippedPaths:
            print('Skipped paths:')
            for skippedPath in skippedPaths:
                print(f'\n{skippedPath}\n')
    def full_analysis_noROI(self):
        """
        Run a full analysis pipeline without ROI filtering.

        This method sequentially executes:
        1. affine_transform()
        2. localize()
        3. colocalize()

        Notes
        -----
        Automatically disables ROI filtering during execution.
        """
        original_roi = self.settings.link_settings.roi
        self.settings.link_settings.roi = False
        self.affine_transform()
        self.localize()
        self.colocalize()
        self.settings.link_settings.roi = original_roi
    def full_analysis_ROI(self):
        """
        Run a full analysis pipeline including ROI filtering. Affine transformation and ROI generation 
        must be done beforehand. 

        This method sequentially executes:
        1. localize()
        2. roi()
        3. colocalize()

        Notes
        -----
        - Requires `.roi` files to be present in the folder.
        """
        pathsROI = natsorted(glob(self.image_folder + '/*.roi', recursive=False))
        if not pathsROI:
            print('Be aware that for this mode you first need to do the .affine_transform and then manually draw ROIs with imageJ freehand tool, and save them as roiX.roi where X is a number starting by 0 and going up to as many ROIs there are')
        else:
            original_roi = self.settings.link_settings.roi
            self.settings.link_settings.roi = True
            self.localize()
            self.roi()
            self.colocalize()
            self.settings.link_settings.roi = original_roi
    def _load_tif(self, file):
        '''
        Load .tif file.
        '''
        ######
        with tiff.TiffFile(file) as ff:
            data = ff.asarray()
        return data  
    def _h_affine_transform(self, image, H):
        """
        Apply an affine transformation.
        """
        return affine_transform(image, H[:2, :2], (H[0, 2], H[1, 2]))  
        
        
class localize_tiff_dataset:
    """
    Manages batch processing of multiple TIFF microscopy datasets within a folder.

    This class acts as a high-level controller for running the full TIFF processing
    pipeline (affine transformation, localization, ROI filtering, and colocalization)
    across all subfolders containing `.tif` files. Each dataset is handled by
    a `localize_tiff_run` instance.

    Attributes
    ----------
    folder : str
        Root directory containing all TIFF datasets and subfolders.
    settings : object
        Configuration object with experiment-specific settings
        (microscope, registration, localization, and colocalization parameters).
    output_folder : str
        Path to the output directory where processed results are saved.

    Methods
    -------
    affine_transform()
        Applies affine transformations to all TIFF datasets found in subfolders.
    localize()
        Runs spot localization on all TIFF datasets.
    roi()
        Restricts localizations to manually drawn ROIs for each dataset.
    colocalize()
        Performs colocalization analysis across all TIFF datasets.
    full_analysis_noROI(mode='tracks')
        Runs the complete analysis pipeline (affine transform → localize → colocalize)
        for all datasets without ROI filtering.
    full_analysis_ROI(mode='tracks')
        Runs the complete analysis pipeline including ROI filtering for all datasets.
    """

    def __init__(self, folder, settings):
        self.folder = folder
        self.settings = settings
    def affine_transform(self):
        """
       Apply affine transformations to all TIFF datasets in the folder.
       """
        directory_path = self.folder
        pathsRaw = glob(directory_path + '/**/**.tif', recursive=True) #Check for each .row file in the folder and subfolders. 
        directory_names = list(set(os.path.dirname(file) for file in pathsRaw)) #makes a lost with the direction to each folder containing .raw files. 
        for path in directory_names:
            if os.path.isdir(path) and 'output' not in path:
                to_process = localize_tiff_run(path, self.settings, directory_path)
                to_process.affine_transform()
        print('########Finished########')
    def localize(self):
        """
       Perform spot localization on all TIFF datasets.
       """
        directory_path = self.folder
        pathsRaw = glob(directory_path + '/**/**.tif', recursive=True) #Check for each .row file in the folder and subfolders. 
        directory_names = list(set(os.path.dirname(file) for file in pathsRaw)) #makes a lost with the direction to each folder containing .raw files. 
        for path in directory_names:
            if os.path.isdir(path) and 'output' not in path:
                to_process = localize_tiff_run(path, self.settings, directory_path)
                to_process.localize()
        print('########Finished########')
    def roi(self):
        """
       Restrict localizations to Regions of Interest (ROIs) for all datasets.
       """
        directory_path = self.folder
        pathsRaw = glob(directory_path + '/**/**.tif', recursive=True) #Check for each .row file in the folder and subfolders. 
        directory_names = list(set(os.path.dirname(file) for file in pathsRaw)) #makes a lost with the direction to each folder containing .raw files. 
        for path in directory_names:
            if os.path.isdir(path) and 'output' not in path:
                print(path)
                to_process = localize_tiff_run(path, self.settings, directory_path)
                to_process.roi()
        print('########Finished########')
    def colocalize(self):
        """
        Perform colocalization analysis for all TIFF datasets.
        """
        directory_path = self.folder
        pathsRaw = glob(directory_path + '/**/**.tif', recursive=True) #Check for each .row file in the folder and subfolders. 
        directory_names = list(set(os.path.dirname(file) for file in pathsRaw)) #makes a lost with the direction to each folder containing .raw files. 
        for path in directory_names:
            if os.path.isdir(path) and 'output' not in path:
                print(path)
                to_process = localize_tiff_run(path, self.settings, directory_path)
                to_process.colocalize()
        print('########Finished########')
    def full_analysis_noROI(self):
        """
        Run the full processing pipeline on all TIFF datasets without ROI filtering.

        Workflow
        ---------
        For each dataset, sequentially runs:
            1. affine_transform()
            2. localize()
            3. colocalize()
        """
        directory_path = self.folder
        pathsRaw = glob(directory_path + '/**/**.tif', recursive=True) #Check for each .row file in the folder and subfolders. 
        directory_names = list(set(os.path.dirname(file) for file in pathsRaw)) #makes a lost with the direction to each folder containing .raw files. 
        for path in directory_names:
            if os.path.isdir(path) and 'output' not in path:
                to_process = localize_tiff_run(path, self.settings, directory_path)
                to_process.full_analysis_noROI()
        print('########Finished########')
    def full_analysis_ROI(self, mode = 'tracks'):
        """
       Run the full processing pipeline with ROI filtering enabled.

       Workflow
       ---------
       For each dataset, sequentially runs:
           1. localize()
           2. roi()
           3. colocalize()
       """
        directory_path = self.folder
        pathsRaw = glob(directory_path + '/**/**.tif', recursive=True) #Check for each .row file in the folder and subfolders. 
        directory_names = list(set(os.path.dirname(file) for file in pathsRaw)) #makes a lost with the direction to each folder containing .raw files. 
        for path in directory_names:
            if os.path.isdir(path) and 'output' not in path:
                print(f"Analyszing {path}")
                to_process = localize_tiff_run(path, self.settings, directory_path)
                to_process.full_analysis_ROI(mode = mode)
        print('########Finished########')
        self.output_folder = os.path.join(self.folder, 'output')